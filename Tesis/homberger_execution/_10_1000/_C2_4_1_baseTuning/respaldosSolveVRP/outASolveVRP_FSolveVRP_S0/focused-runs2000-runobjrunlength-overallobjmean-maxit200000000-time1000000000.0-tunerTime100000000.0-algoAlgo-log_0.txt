Call: /usr/bin/ruby ../scripts/param_ils_2_3_run.rb "-numRun" "0" "-approach" "focused" "-userunlog" "1" "-validN" "0" "-pruning" "0" "-maxEvals" "1000" "-scenariofile" "../_C2_4_1_baseTuning/scn/SolveVRP.scn"


seed: 1234
algo: bash SolveVRP.sh
tunerTimeout (CPU time): 100000000.0
maxWallTime: 8640000.0
maxEvals: 1000
run_obj: runlength
overall_obj: mean
instance_file: inst/single.inst
test_instance_file: inst/single.inst
N: 2000
cutoff_time: 1000000000.0
cutoff_length: 2147483647
R: 10
pertubation_strength_basic: 
pertubation_strength_scaling: false
p_restart: 0.01
Run 1
Level 
========================================================
Starting ILS for level 1, i.e. a limit of N=2000, and cutoff time=1000000000.0.
Current CPU time = 0, this run goes until 100000000.0 
========================================================
New Incumbent: 0, 100000000 [0, 0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
 Same incumbent, new precision:
New Incumbent: 0.1, 4088.0 [1, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> Take improving step to random gs=70 nc=0.8 ne=0.8 ps=5 xi=0.2 (4088.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=20 nc=0.2 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=100 nc=0.4 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 1 runs with cutoff 1000000000.0])

        -> Worse random: gs=100 nc=0.1 ne=0.2 ps=25 xi=0.1 (4092.0 [based on 1 runs with cutoff 1000000000.0])
          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=25 xi=0.6 (4088.0 [based on 1 runs with cutoff 1000000000.0])

        -> Worse random: gs=70 nc=0.1 ne=0.2 ps=35 xi=0.1 (4092.0 [based on 1 runs with cutoff 1000000000.0])
        -> Worse random: gs=70 nc=0.4 ne=0.6 ps=45 xi=0.2 (4123.0 [based on 1 runs with cutoff 1000000000.0])
          -> Take improving step to random gs=70 nc=0.6 ne=0.6 ps=25 xi=0.2 (4088.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0])

        -> Worse random: gs=20 nc=0.8 ne=0.1 ps=45 xi=0.2 (4139.0 [based on 1 runs with cutoff 1000000000.0])
   BLS in iteration 1, start with gs=70 nc=0.8 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["nc: 0.8->0.2"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.2 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0]) with flip 1

          
============= Performing 1 bonus runs of state: gs=70 nc=0.2 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0]) ============ 

State wants more detail (1+1) than incumbent (1), doing incumbent first:
gs=70 nc=0.2 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 1 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 1 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.3, 4088.0 [2, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.2 ne=0.4 ps=35 xi=0.8 (4088.0 [based on 2 runs with cutoff 1000000000.0])

    Changing ["ps: 35->15"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.2 ne=0.4 ps=15 xi=0.8 (4088.0 [based on 2 runs with cutoff 1000000000.0]) with flip 2

          
============= Performing 1 bonus runs of state: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.8 (4088.0 [based on 2 runs with cutoff 1000000000.0]) ============ 

State wants more detail (2+1) than incumbent (2), doing incumbent first:
gs=70 nc=0.2 ne=0.4 ps=15 xi=0.8 (4088.0 [based on 2 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 2 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.7000000000000004, 4088.0 [3, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.8 (4088.0 [based on 3 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.1"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.2 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 3 runs with cutoff 1000000000.0]) with flip 3

          
============= Performing 1 bonus runs of state: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 3 runs with cutoff 1000000000.0]) ============ 

State wants more detail (3+1) than incumbent (3), doing incumbent first:
gs=70 nc=0.2 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 3 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 3 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 2.2000000000000006, 4088.0 [4, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 4 runs with cutoff 1000000000.0])

    Changing ["ne: 0.4->0.2"], evaluating ...
        -> worse: (4093.25 [based on 4 runs with cutoff 1000000000.0])
    Changing ["ne: 0.4->0.1"], evaluating ...
        -> worse: (4107.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["ps: 15->35"], evaluating ...
        -> worse: (4097.0 [based on 4 runs with cutoff 1000000000.0])
    Changing ["nc: 0.2->0.6"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 4 runs with cutoff 1000000000.0]) with flip 4

          
============= Performing 4 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 4 runs with cutoff 1000000000.0]) ============ 

State wants more detail (4+1) than incumbent (4), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 4 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 4 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 3.700000000000002, 4088.0 [5, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (5+1) than incumbent (5), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 5 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 5 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 3.900000000000002, 4088.0 [6, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (6+1) than incumbent (6), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 6 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 6 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 4.100000000000001, 4088.0 [7, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (7+1) than incumbent (7), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 7 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 7 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 4.300000000000001, 4088.0 [8, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 4 bonus runs: gs=70 nc=0.6 ne=0.4 ps=15 xi=0.1 (4088.0 [based on 8 runs with cutoff 1000000000.0])

    Changing ["ps: 15->5"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 8 runs with cutoff 1000000000.0]) with flip 5

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 8 runs with cutoff 1000000000.0]) ============ 

State wants more detail (8+1) than incumbent (8), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 8 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 8 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 5.299999999999997, 4088.0 [9, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 9 runs with cutoff 1000000000.0])

    Changing ["xi: 0.1->0.8"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=5 xi=0.8 (4088.0 [based on 9 runs with cutoff 1000000000.0]) with flip 6

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.8 (4088.0 [based on 9 runs with cutoff 1000000000.0]) ============ 

State wants more detail (9+1) than incumbent (9), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=5 xi=0.8 (4088.0 [based on 9 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 9 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 6.399999999999993, 4088.0 [10, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.8 (4088.0 [based on 10 runs with cutoff 1000000000.0])

    Changing ["ps: 5->45"], evaluating ...
        -> worse: (4090.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["xi: 0.8->0.4"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 10 runs with cutoff 1000000000.0]) with flip 7

          
============= Performing 2 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 10 runs with cutoff 1000000000.0]) ============ 

State wants more detail (10+1) than incumbent (10), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 10 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 10 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 7.699999999999989, 4088.0 [11, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (11+1) than incumbent (11), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 11 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 11 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 7.899999999999988, 4088.0 [12, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 12 runs with cutoff 1000000000.0])

    Changing ["xi: 0.4->0.6"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 12 runs with cutoff 1000000000.0]) with flip 8

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 12 runs with cutoff 1000000000.0]) ============ 

State wants more detail (12+1) than incumbent (12), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 12 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 12 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 9.299999999999983, 4088.0 [13, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 13 runs with cutoff 1000000000.0])

    Changing ["ps: 5->35"], evaluating ...
        -> worse: (4090.5 [based on 6 runs with cutoff 1000000000.0])
    Changing ["gs: 70->40"], evaluating ...
101/1000, 10.09999999999998/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 13 runs with cutoff 1000000000.0]) with flip 9

          
============= Performing 2 bonus runs of state: gs=40 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 13 runs with cutoff 1000000000.0]) ============ 

State wants more detail (13+1) than incumbent (13), doing incumbent first:
gs=40 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 13 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 13 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 11.399999999999975, 4088.0 [14, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (14+1) than incumbent (14), doing incumbent first:
gs=40 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 14 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 14 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 11.599999999999975, 4088.0 [15, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=40 nc=0.6 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 15 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.2"], evaluating ...
        -> worse: (4092.8 [based on 10 runs with cutoff 1000000000.0])
    Changing ["ps: 5->35"], evaluating ...
        -> worse: (4088.3333333333335 [based on 6 runs with cutoff 1000000000.0])
    Changing ["nc: 0.6->0.8"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 15 runs with cutoff 1000000000.0]) with flip 10

          
============= Performing 3 bonus runs of state: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 15 runs with cutoff 1000000000.0]) ============ 

State wants more detail (15+1) than incumbent (15), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 15 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 15 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 14.899999999999963, 4088.0 [16, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (16+1) than incumbent (16), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 16 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 16 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 15.099999999999962, 4088.0 [17, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (17+1) than incumbent (17), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 17 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 17 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 15.299999999999962, 4088.0 [18, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 3 bonus runs: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.6 (4088.0 [based on 18 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.1"], evaluating ...
        -> worse: (4092.0 [based on 16 runs with cutoff 1000000000.0])
    Changing ["gs: 40->100"], evaluating ...
        -> worse: (4088.3076923076924 [based on 13 runs with cutoff 1000000000.0])
    Changing ["ne: 0.4->0.1"], evaluating ...
        -> worse: (4090.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["xi: 0.6->0.4"], evaluating ...
201/1000, 20.100000000000016/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 18 runs with cutoff 1000000000.0]) with flip 11

          
============= Performing 4 bonus runs of state: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 18 runs with cutoff 1000000000.0]) ============ 

State wants more detail (18+1) than incumbent (18), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 18 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 18 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 20.30000000000002, 4088.0 [19, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (19+1) than incumbent (19), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 19 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 19 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 20.50000000000002, 4088.0 [20, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (20+1) than incumbent (20), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 20 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 20 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 20.700000000000024, 4088.0 [21, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (21+1) than incumbent (21), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 21 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 21 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 20.900000000000027, 4088.0 [22, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 4 bonus runs: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.4 (4088.0 [based on 22 runs with cutoff 1000000000.0])

    Changing ["ps: 5->45"], evaluating ...
        -> worse: (4093.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.1"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 22 runs with cutoff 1000000000.0]) with flip 12

          
============= Performing 2 bonus runs of state: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 22 runs with cutoff 1000000000.0]) ============ 

State wants more detail (22+1) than incumbent (22), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 22 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 22 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 23.400000000000063, 4088.0 [23, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (23+1) than incumbent (23), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 23 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 23 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 23.600000000000065, 4088.0 [24, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=40 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 24 runs with cutoff 1000000000.0])

    Changing ["ps: 5->45"], evaluating ...
        -> worse: (4088.4 [based on 5 runs with cutoff 1000000000.0])
    Changing ["gs: 40->70"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 24 runs with cutoff 1000000000.0]) with flip 13

          
============= Performing 2 bonus runs of state: gs=70 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 24 runs with cutoff 1000000000.0]) ============ 

State wants more detail (24+1) than incumbent (24), doing incumbent first:
gs=70 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 24 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 24 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 26.70000000000011, 4088.0 [25, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (25+1) than incumbent (25), doing incumbent first:
gs=70 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 25 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 25 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 26.900000000000112, 4088.0 [26, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=70 nc=0.8 ne=0.4 ps=5 xi=0.1 (4088.0 [based on 26 runs with cutoff 1000000000.0])

    Changing ["ne: 0.4->0.6"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.8 ne=0.6 ps=5 xi=0.1 (4088.0 [based on 26 runs with cutoff 1000000000.0]) with flip 14

          
============= Performing 1 bonus runs of state: gs=70 nc=0.8 ne=0.6 ps=5 xi=0.1 (4088.0 [based on 26 runs with cutoff 1000000000.0]) ============ 

State wants more detail (26+1) than incumbent (26), doing incumbent first:
gs=70 nc=0.8 ne=0.6 ps=5 xi=0.1 (4088.0 [based on 26 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 26 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 29.700000000000152, 4088.0 [27, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.8 ne=0.6 ps=5 xi=0.1 (4088.0 [based on 27 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.1"], evaluating ...
        -> worse: (4093.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["xi: 0.1->0.8"], evaluating ...
301/1000, 30.100000000000158/100000000.0
          -> Take improving step to neighbour gs=70 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 27 runs with cutoff 1000000000.0]) with flip 15

          
============= Performing 2 bonus runs of state: gs=70 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 27 runs with cutoff 1000000000.0]) ============ 

State wants more detail (27+1) than incumbent (27), doing incumbent first:
gs=70 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 27 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 27 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 32.700000000000195, 4088.0 [28, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (28+1) than incumbent (28), doing incumbent first:
gs=70 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 28 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 28 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 32.9000000000002, 4088.0 [29, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=70 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 29 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.6"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 29 runs with cutoff 1000000000.0]) with flip 16

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 29 runs with cutoff 1000000000.0]) ============ 

State wants more detail (29+1) than incumbent (29), doing incumbent first:
gs=70 nc=0.6 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 29 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 29 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 36.00000000000024, 4088.0 [30, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 30 runs with cutoff 1000000000.0])

    Changing ["ne: 0.6->0.8"], evaluating ...
        -> worse: (4089.655172413793 [based on 29 runs with cutoff 1000000000.0])
    Changing ["ps: 5->45"], evaluating ...
        -> worse: (4089.0 [based on 2 runs with cutoff 1000000000.0])
    Changing ["ne: 0.6->0.2"], evaluating ...
401/1000, 40.1000000000003/100000000.0
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 30 runs with cutoff 1000000000.0]) with flip 17

          
============= Performing 3 bonus runs of state: gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 30 runs with cutoff 1000000000.0]) ============ 

State wants more detail (30+1) than incumbent (30), doing incumbent first:
gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 30 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 30 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 42.30000000000033, 4088.0 [31, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (31+1) than incumbent (31), doing incumbent first:
gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 31 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 31 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 42.500000000000334, 4088.0 [32, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (32+1) than incumbent (32), doing incumbent first:
gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 32 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 32 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 42.70000000000034, 4088.0 [33, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 3 bonus runs: gs=70 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 33 runs with cutoff 1000000000.0])

    Changing ["gs: 70->10"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 33 runs with cutoff 1000000000.0]) with flip 18

          
============= Performing 1 bonus runs of state: gs=10 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 33 runs with cutoff 1000000000.0]) ============ 

State wants more detail (33+1) than incumbent (33), doing incumbent first:
gs=10 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 33 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 33 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 46.20000000000039, 4088.0 [34, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 34 runs with cutoff 1000000000.0])

    Changing ["gs: 10->40"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 34 runs with cutoff 1000000000.0]) with flip 19

          
============= Performing 1 bonus runs of state: gs=40 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 34 runs with cutoff 1000000000.0]) ============ 

State wants more detail (34+1) than incumbent (34), doing incumbent first:
gs=40 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 34 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 34 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 49.80000000000044, 4088.0 [35, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.6 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 35 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.4"], evaluating ...
501/1000, 50.10000000000044/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.6 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 35 runs with cutoff 1000000000.0]) with flip 20

          
============= Performing 1 bonus runs of state: gs=40 nc=0.6 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 35 runs with cutoff 1000000000.0]) ============ 

State wants more detail (35+1) than incumbent (35), doing incumbent first:
gs=40 nc=0.6 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 35 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 35 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 53.50000000000049, 4088.0 [36, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.6 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 36 runs with cutoff 1000000000.0])

    Changing ["xi: 0.4->0.2"], evaluating ...
        -> worse: (4088.0714285714284 [based on 28 runs with cutoff 1000000000.0])
    Changing ["nc: 0.6->0.8"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 36 runs with cutoff 1000000000.0]) with flip 21

          
============= Performing 2 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 36 runs with cutoff 1000000000.0]) ============ 

State wants more detail (36+1) than incumbent (36), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 36 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 36 runs with cutoff 1000000000.0])
601/1000, 60.100000000000584/100000000.0
 Same incumbent, new precision:
New Incumbent: 60.100000000000584, 4088.0 [37, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (37+1) than incumbent (37), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 37 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 37 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 60.30000000000059, 4088.0 [38, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=40 nc=0.8 ne=0.2 ps=5 xi=0.4 (4088.0 [based on 38 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.1"], evaluating ...
        -> worse: (4104.5 [based on 4 runs with cutoff 1000000000.0])
    Changing ["ne: 0.2->0.1"], evaluating ...
        -> worse: (4090.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.8"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 38 runs with cutoff 1000000000.0]) with flip 22

          
============= Performing 3 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 38 runs with cutoff 1000000000.0]) ============ 

State wants more detail (38+1) than incumbent (38), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 38 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 38 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 64.8000000000006, 4088.0 [39, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (39+1) than incumbent (39), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 39 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 39 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 65.00000000000058, 4088.0 [40, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (40+1) than incumbent (40), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 40 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 40 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 65.20000000000057, 4088.0 [41, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 3 bonus runs: gs=40 nc=0.8 ne=0.2 ps=5 xi=0.8 (4088.0 [based on 41 runs with cutoff 1000000000.0])

    Changing ["gs: 40->10"], evaluating ...
        -> worse: (4089.7567567567567 [based on 37 runs with cutoff 1000000000.0])
    Changing ["ne: 0.2->0.6"], evaluating ...
702/1000, 70.20000000000029/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 41 runs with cutoff 1000000000.0]) with flip 23

          
============= Performing 2 bonus runs of state: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 41 runs with cutoff 1000000000.0]) ============ 

State wants more detail (41+1) than incumbent (41), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 41 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (4088.0 [based on 41 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 73.20000000000012, 4088.0476190476193 [42, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
New inc: 4088.0
New Incumbent: 73.30000000000011, 4088.0 [42, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
 Same incumbent, new precision:
New Incumbent: 73.4000000000001, 4088.0 [43, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
          -> After 2 bonus runs: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 43 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.4"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.6 ps=5 xi=0.4 (4088.0 [based on 43 runs with cutoff 1000000000.0]) with flip 24

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.4 (4088.0 [based on 43 runs with cutoff 1000000000.0]) ============ 

State wants more detail (43+1) than incumbent (43), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.4 (4088.0 [based on 43 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 43 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 77.79999999999986, 4088.0 [44, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.4 (4088.0 [based on 44 runs with cutoff 1000000000.0])

    Changing ["gs: 40->20"], evaluating ...
        -> worse: (4099.454545454545 [based on 11 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.1"], evaluating ...
803/1000, 80.29999999999971/100000000.0
        -> worse: (4089.560975609756 [based on 41 runs with cutoff 1000000000.0])
    Changing ["nc: 0.8->0.1"], evaluating ...
        -> worse: (4101.8 [based on 5 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.6"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 44 runs with cutoff 1000000000.0]) with flip 25

          
============= Performing 4 bonus runs of state: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 44 runs with cutoff 1000000000.0]) ============ 

State wants more detail (44+1) than incumbent (44), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 44 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 44 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 88.09999999999927, 4088.0 [45, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
State wants more detail (45+1) than incumbent (45), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 45 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 45 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 88.29999999999926, 4088.0 [46, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
State wants more detail (46+1) than incumbent (46), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 46 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 46 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 88.49999999999925, 4088.0 [47, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
State wants more detail (47+1) than incumbent (47), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 47 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 47 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 88.69999999999924, 4088.0 [48, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
          -> After 4 bonus runs: gs=40 nc=0.8 ne=0.6 ps=5 xi=0.6 (4088.0 [based on 48 runs with cutoff 1000000000.0])

    Changing ["ps: 5->15"], evaluating ...
904/1000, 90.39999999999914/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.6 ps=15 xi=0.6 (4088.0 [based on 48 runs with cutoff 1000000000.0]) with flip 26

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.6 ps=15 xi=0.6 (4088.0 [based on 48 runs with cutoff 1000000000.0]) ============ 

State wants more detail (48+1) than incumbent (48), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=15 xi=0.6 (4088.0 [based on 48 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 48 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 93.69999999999895, 4088.0 [49, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.6 ps=15 xi=0.6 (4088.0 [based on 49 runs with cutoff 1000000000.0])

    Changing ["ne: 0.6->0.2"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 49 runs with cutoff 1000000000.0]) with flip 27

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 49 runs with cutoff 1000000000.0]) ============ 

State wants more detail (49+1) than incumbent (49), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 49 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 49 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 98.79999999999866, 4088.0 [50, 1000000000.0]. With state gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 50 runs with cutoff 1000000000.0])

    Changing ["ps: 15->25"], evaluating ...
        -> worse: (4088.3333333333335 [based on 6 runs with cutoff 1000000000.0])
    Changing ["gs: 40->10"], evaluating ...
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
        -> worse: (4088.0 [based on 5 runs with cutoff 1000000000.0])
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          
============= Performing 2 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 50 runs with cutoff 1000000000.0]) ============ 

ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          -> After 2 bonus runs for LM: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 50 runs with cutoff 1000000000.0])

   LM for iteration 1: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 50 runs with cutoff 1000000000.0])

========== DETAILED RESULTS (iteration 1): ==========
================================================

==================================================================
Best parameter configuration found so far (end of iteration 1): gs=40, nc=0.8, ne=0.6, ps=5, xi=0.8
==================================================================
Training quality of this incumbent parameter configuration: 4088.0, based on 50 runs with cutoff 1000000000.0
==================================================================

Comparing LM against incumbent:
gs=40 nc=0.8 ne=0.2 ps=15 xi=0.6 (4088.0 [based on 50 runs with cutoff 1000000000.0])
gs=40 nc=0.8 ne=0.6 ps=5 xi=0.8 (4088.0 [based on 50 runs with cutoff 1000000000.0])
LM better, change incumbent
New Incumbent: 99.9999999999986, 4088.0 [50, 1000000000.0]. With state gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
Final solution for depth 1 with limit N=2000, and cutoff time=1000000000.0.
New Incumbent: 99.9999999999986, 4088.0 [50, 1000000000.0]. With state gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6

==================================================================
ParamILS is finished.
==================================================================

Final best parameter configuration found: gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6
==================================================================
Active parameters: gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6

==================================================================
Training quality of this final best found parameter configuration: 4088.0, based on 50 runs with cutoff 1000000000.0
==================================================================


==================================================================
Computing validation result on independent data -- 0 runs with cutoff time 1000000000.0...
==================================================================
Combined result: 1000000000000000000

================================================================
Final best parameter configuration: gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6
==================================================================
Active parameters: gs=40, nc=0.8, ne=0.2, ps=15, xi=0.6

================================================================
Training quality of this final best found parameter configuration: 4088.0, based on 50 runs with cutoff 1000000000.0
Test quality of this final best found parameter configuration: 1000000000000000000, based on 0 independent runs with cutoff 1000000000.0
==================================================================
