Call: /usr/bin/ruby ../scripts/param_ils_2_3_run.rb "-numRun" "0" "-approach" "focused" "-userunlog" "1" "-validN" "0" "-pruning" "0" "-maxEvals" "1000" "-scenariofile" "../_C1_6_6_baseTuning/scn/SolveVRP.scn"


seed: 1234
algo: bash SolveVRP.sh
tunerTimeout (CPU time): 100000000.0
maxWallTime: 8640000.0
maxEvals: 1000
run_obj: runlength
overall_obj: mean
instance_file: inst/single.inst
test_instance_file: inst/single.inst
N: 2000
cutoff_time: 1000000000.0
cutoff_length: 2147483647
R: 10
pertubation_strength_basic: 
pertubation_strength_scaling: false
p_restart: 0.01
Run 1
Level 
========================================================
Starting ILS for level 1, i.e. a limit of N=2000, and cutoff time=1000000000.0.
Current CPU time = 0, this run goes until 100000000.0 
========================================================
New Incumbent: 0, 100000000 [0, 0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
 Same incumbent, new precision:
New Incumbent: 0.1, 14039.0 [1, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> Take improving step to random gs=70 nc=0.8 ne=0.8 ps=5 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=20 nc=0.2 ne=0.4 ps=35 xi=0.8 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=100 nc=0.4 ne=0.4 ps=5 xi=0.1 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=100 nc=0.1 ne=0.2 ps=25 xi=0.1 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=25 xi=0.6 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.1 ne=0.2 ps=35 xi=0.1 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.4 ne=0.6 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.6 ne=0.6 ps=25 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=35 xi=0.8 (14039.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=20 nc=0.8 ne=0.1 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])

   BLS in iteration 1, start with gs=20 nc=0.8 ne=0.1 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["nc: 0.8->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0]) with flip 1

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0]) ============ 

State wants more detail (1+1) than incumbent (1), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (14039.0 [based on 1 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 1 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.3, 14039.0 [2, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (14041.5 [based on 2 runs with cutoff 1000000000.0])

    Changing ["ps: 45->15"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (14039.5 [based on 2 runs with cutoff 1000000000.0]) with flip 2

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (14039.5 [based on 2 runs with cutoff 1000000000.0]) ============ 

State wants more detail (2+1) than incumbent (2), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (14039.5 [based on 2 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 2 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.7000000000000004, 14039.0 [3, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (14039.333333333334 [based on 3 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.1"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (14039.0 [based on 3 runs with cutoff 1000000000.0]) with flip 3

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (14039.0 [based on 3 runs with cutoff 1000000000.0]) ============ 

State wants more detail (3+1) than incumbent (3), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (14039.0 [based on 3 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 3 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 2.2000000000000006, 14039.0 [4, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (14039.0 [based on 4 runs with cutoff 1000000000.0])

    Changing ["ne: 0.1->0.4"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 4 runs with cutoff 1000000000.0]) with flip 4

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 4 runs with cutoff 1000000000.0]) ============ 

State wants more detail (4+1) than incumbent (4), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 4 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 4 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 2.800000000000001, 14039.0 [5, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 5 runs with cutoff 1000000000.0])

    Changing ["ps: 15->25"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (14039.0 [based on 5 runs with cutoff 1000000000.0]) with flip 5

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (14039.0 [based on 5 runs with cutoff 1000000000.0]) ============ 

State wants more detail (5+1) than incumbent (5), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (14039.0 [based on 5 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 5 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 3.5000000000000018, 14039.0 [6, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (14039.833333333334 [based on 6 runs with cutoff 1000000000.0])

    Changing ["nc: 0.2->0.6"], evaluating ...
        -> worse: (14043.333333333334 [based on 3 runs with cutoff 1000000000.0])
    Changing ["xi: 0.1->0.4"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 6 runs with cutoff 1000000000.0]) with flip 6

          
============= Performing 2 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 6 runs with cutoff 1000000000.0]) ============ 

State wants more detail (6+1) than incumbent (6), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 6 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 6 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 4.6, 14039.0 [7, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (7+1) than incumbent (7), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 7 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 7 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 4.799999999999999, 14039.0 [8, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 8 runs with cutoff 1000000000.0])

    Changing ["xi: 0.4->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=25 xi=0.2 (14039.0 [based on 8 runs with cutoff 1000000000.0]) with flip 7

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.2 (14039.0 [based on 8 runs with cutoff 1000000000.0]) ============ 

State wants more detail (8+1) than incumbent (8), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.2 (14039.0 [based on 8 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 8 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 5.799999999999995, 14039.0 [9, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.2 (14039.0 [based on 9 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.6"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=25 xi=0.6 (14039.0 [based on 9 runs with cutoff 1000000000.0]) with flip 8

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.6 (14039.0 [based on 9 runs with cutoff 1000000000.0]) ============ 

State wants more detail (9+1) than incumbent (9), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.6 (14039.0 [based on 9 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 9 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 6.8999999999999915, 14039.0 [10, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.6 (14039.0 [based on 10 runs with cutoff 1000000000.0])

    Changing ["ps: 25->35"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 10 runs with cutoff 1000000000.0]) with flip 9

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 10 runs with cutoff 1000000000.0]) ============ 

State wants more detail (10+1) than incumbent (10), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 10 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 10 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 8.099999999999987, 14039.0 [11, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 11 runs with cutoff 1000000000.0])

    Changing ["gs: 20->70"], evaluating ...
        -> worse: (14039.625 [based on 8 runs with cutoff 1000000000.0])
    Changing ["nc: 0.2->0.6"], evaluating ...
101/1000, 10.09999999999998/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 11 runs with cutoff 1000000000.0]) with flip 10

          
============= Performing 2 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 11 runs with cutoff 1000000000.0]) ============ 

State wants more detail (11+1) than incumbent (11), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 11 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 11 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 10.19999999999998, 14039.0 [12, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (12+1) than incumbent (12), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 12 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 12 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 10.399999999999979, 14039.0 [13, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=20 nc=0.6 ne=0.4 ps=35 xi=0.6 (14039.0 [based on 13 runs with cutoff 1000000000.0])

    Changing ["ps: 35->15"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 13 runs with cutoff 1000000000.0]) with flip 11

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 13 runs with cutoff 1000000000.0]) ============ 

State wants more detail (13+1) than incumbent (13), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 13 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 13 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 11.899999999999974, 14039.0 [14, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 14 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.4"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 14 runs with cutoff 1000000000.0]) with flip 12

          
============= Performing 1 bonus runs of state: gs=20 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 14 runs with cutoff 1000000000.0]) ============ 

State wants more detail (14+1) than incumbent (14), doing incumbent first:
gs=20 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 14 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 14 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 13.499999999999968, 14039.0 [15, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 15 runs with cutoff 1000000000.0])

    Changing ["nc: 0.4->0.8"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.8 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 15 runs with cutoff 1000000000.0]) with flip 13

          
============= Performing 1 bonus runs of state: gs=20 nc=0.8 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 15 runs with cutoff 1000000000.0]) ============ 

State wants more detail (15+1) than incumbent (15), doing incumbent first:
gs=20 nc=0.8 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 15 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 15 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 15.199999999999962, 14039.0 [16, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.8 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 16 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.1"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 16 runs with cutoff 1000000000.0]) with flip 14

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 16 runs with cutoff 1000000000.0]) ============ 

State wants more detail (16+1) than incumbent (16), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 16 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 16 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 16.99999999999997, 14039.0 [17, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 17 runs with cutoff 1000000000.0])

    Changing ["gs: 20->100"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 17 runs with cutoff 1000000000.0]) with flip 15

          
============= Performing 1 bonus runs of state: gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 17 runs with cutoff 1000000000.0]) ============ 

State wants more detail (17+1) than incumbent (17), doing incumbent first:
gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 17 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 17 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 18.9, 14039.0 [18, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 18 runs with cutoff 1000000000.0])

    Changing ["nc: 0.1->0.4"], evaluating ...
201/1000, 20.100000000000016/100000000.0
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 18 runs with cutoff 1000000000.0]) with flip 16

          
============= Performing 1 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 18 runs with cutoff 1000000000.0]) ============ 

State wants more detail (18+1) than incumbent (18), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 18 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 18 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 20.900000000000027, 14039.0 [19, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (14039.0 [based on 19 runs with cutoff 1000000000.0])

    Changing ["ps: 15->35"], evaluating ...
        -> worse: (14039.166666666666 [based on 6 runs with cutoff 1000000000.0])
    Changing ["xi: 0.6->0.1"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 19 runs with cutoff 1000000000.0]) with flip 17

          
============= Performing 2 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 19 runs with cutoff 1000000000.0]) ============ 

State wants more detail (19+1) than incumbent (19), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 19 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 19 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 23.600000000000065, 14039.0 [20, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (20+1) than incumbent (20), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 20 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 20 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 23.800000000000068, 14039.0 [21, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.1 (14039.0 [based on 21 runs with cutoff 1000000000.0])

    Changing ["ps: 15->45"], evaluating ...
        -> worse: (14039.142857142857 [based on 7 runs with cutoff 1000000000.0])
    Changing ["xi: 0.1->0.2"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 21 runs with cutoff 1000000000.0]) with flip 18

          
============= Performing 2 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 21 runs with cutoff 1000000000.0]) ============ 

State wants more detail (21+1) than incumbent (21), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 21 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 21 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 26.80000000000011, 14039.0 [22, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (22+1) than incumbent (22), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 22 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 22 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 27.000000000000114, 14039.0 [23, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 23 runs with cutoff 1000000000.0])

    Changing ["gs: 100->40"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 23 runs with cutoff 1000000000.0]) with flip 19

          
============= Performing 1 bonus runs of state: gs=40 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 23 runs with cutoff 1000000000.0]) ============ 

State wants more detail (23+1) than incumbent (23), doing incumbent first:
gs=40 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 23 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 23 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 29.50000000000015, 14039.0 [24, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.4 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 24 runs with cutoff 1000000000.0])

    Changing ["ne: 0.4->0.6"], evaluating ...
301/1000, 30.100000000000158/100000000.0
        -> worse: (14039.764705882353 [based on 17 runs with cutoff 1000000000.0])
    Changing ["nc: 0.4->0.1"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.1 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 24 runs with cutoff 1000000000.0]) with flip 20

          
============= Performing 2 bonus runs of state: gs=40 nc=0.1 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 24 runs with cutoff 1000000000.0]) ============ 

State wants more detail (24+1) than incumbent (24), doing incumbent first:
gs=40 nc=0.1 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 24 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 24 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 33.80000000000021, 14039.0 [25, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (25+1) than incumbent (25), doing incumbent first:
gs=40 nc=0.1 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 25 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 25 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 34.00000000000021, 14039.0 [26, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=40 nc=0.1 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 26 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.6"], evaluating ...
        -> worse: (14039.764705882353 [based on 17 runs with cutoff 1000000000.0])
    Changing ["nc: 0.1->0.8"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 26 runs with cutoff 1000000000.0]) with flip 21

          
============= Performing 2 bonus runs of state: gs=40 nc=0.8 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 26 runs with cutoff 1000000000.0]) ============ 

State wants more detail (26+1) than incumbent (26), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 26 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 26 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 38.50000000000028, 14039.0 [27, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (27+1) than incumbent (27), doing incumbent first:
gs=40 nc=0.8 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 27 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 27 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 38.70000000000028, 14039.0 [28, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=40 nc=0.8 ne=0.4 ps=15 xi=0.2 (14039.0 [based on 28 runs with cutoff 1000000000.0])

    Changing ["ne: 0.4->0.8"], evaluating ...
        -> worse: (14041.6 [based on 5 runs with cutoff 1000000000.0])
    Changing ["ps: 15->45"], evaluating ...
        -> worse: (14039.2 [based on 5 runs with cutoff 1000000000.0])
    Changing ["ne: 0.4->0.2"], evaluating ...
401/1000, 40.1000000000003/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 28 runs with cutoff 1000000000.0]) with flip 22

          
============= Performing 3 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 28 runs with cutoff 1000000000.0]) ============ 

State wants more detail (28+1) than incumbent (28), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 28 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 28 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 42.70000000000034, 14039.0 [29, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (29+1) than incumbent (29), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 29 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 29 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 42.90000000000034, 14039.0 [30, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (30+1) than incumbent (30), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 30 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 30 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 43.10000000000034, 14039.0 [31, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 3 bonus runs: gs=40 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 31 runs with cutoff 1000000000.0])

    Changing ["gs: 40->10"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 31 runs with cutoff 1000000000.0]) with flip 23

          
============= Performing 1 bonus runs of state: gs=10 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 31 runs with cutoff 1000000000.0]) ============ 

State wants more detail (31+1) than incumbent (31), doing incumbent first:
gs=10 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 31 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 31 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 46.40000000000039, 14039.0 [32, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.8 ne=0.2 ps=15 xi=0.2 (14039.0 [based on 32 runs with cutoff 1000000000.0])

    Changing ["gs: 10->70"], evaluating ...
        -> worse: (14039.1 [based on 10 runs with cutoff 1000000000.0])
    Changing ["xi: 0.2->0.8"], evaluating ...
501/1000, 50.10000000000044/100000000.0
          -> Take improving step to neighbour gs=10 nc=0.8 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 32 runs with cutoff 1000000000.0]) with flip 24

          
============= Performing 2 bonus runs of state: gs=10 nc=0.8 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 32 runs with cutoff 1000000000.0]) ============ 

State wants more detail (32+1) than incumbent (32), doing incumbent first:
gs=10 nc=0.8 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 32 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 32 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 50.80000000000045, 14039.0 [33, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (33+1) than incumbent (33), doing incumbent first:
gs=10 nc=0.8 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 33 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 33 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 51.000000000000455, 14039.0 [34, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=10 nc=0.8 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 34 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.6"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.6 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 34 runs with cutoff 1000000000.0]) with flip 25

          
============= Performing 1 bonus runs of state: gs=10 nc=0.6 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 34 runs with cutoff 1000000000.0]) ============ 

State wants more detail (34+1) than incumbent (34), doing incumbent first:
gs=10 nc=0.6 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 34 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 34 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 54.600000000000506, 14039.0 [35, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.6 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 35 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.1"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 35 runs with cutoff 1000000000.0]) with flip 26

          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 35 runs with cutoff 1000000000.0]) ============ 

State wants more detail (35+1) than incumbent (35), doing incumbent first:
gs=10 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 35 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 35 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 58.30000000000056, 14039.0 [36, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 36 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.4"], evaluating ...
601/1000, 60.100000000000584/100000000.0
          -> Take improving step to neighbour gs=10 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 36 runs with cutoff 1000000000.0]) with flip 27

          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 36 runs with cutoff 1000000000.0]) ============ 

State wants more detail (36+1) than incumbent (36), doing incumbent first:
gs=10 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 36 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 36 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 62.10000000000061, 14039.0 [37, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 37 runs with cutoff 1000000000.0])

    Changing ["gs: 10->20"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 37 runs with cutoff 1000000000.0]) with flip 28

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 37 runs with cutoff 1000000000.0]) ============ 

State wants more detail (37+1) than incumbent (37), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 37 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 37 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 66.00000000000053, 14039.0 [38, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.2 ps=15 xi=0.4 (14039.0 [based on 38 runs with cutoff 1000000000.0])

    Changing ["ne: 0.2->0.4"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.4 ps=15 xi=0.4 (14039.0 [based on 38 runs with cutoff 1000000000.0]) with flip 29

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.4 (14039.0 [based on 38 runs with cutoff 1000000000.0]) ============ 

State wants more detail (38+1) than incumbent (38), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.4 (14039.0 [based on 38 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 38 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 70.0000000000003, 14039.0 [39, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.4 (14039.0 [based on 39 runs with cutoff 1000000000.0])

    Changing ["gs: 20->40"], evaluating ...
702/1000, 70.20000000000029/100000000.0
        -> worse: (14039.764705882353 [based on 17 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.1"], evaluating ...
        -> worse: (14039.361111111111 [based on 36 runs with cutoff 1000000000.0])
    Changing ["nc: 0.1->0.2"], evaluating ...
        -> worse: (14045.5 [based on 2 runs with cutoff 1000000000.0])
    Changing ["xi: 0.4->0.8"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 39 runs with cutoff 1000000000.0]) with flip 30

          
============= Performing 4 bonus runs of state: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 39 runs with cutoff 1000000000.0]) ============ 

State wants more detail (39+1) than incumbent (39), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 39 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 39 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 79.59999999999975, 14039.0 [40, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (40+1) than incumbent (40), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 40 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 40 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 79.79999999999974, 14039.0 [41, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (41+1) than incumbent (41), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 41 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 41 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 79.99999999999973, 14039.0 [42, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (42+1) than incumbent (42), doing incumbent first:
gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 42 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 42 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 80.19999999999972, 14039.0 [43, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
803/1000, 80.29999999999971/100000000.0
          -> After 4 bonus runs: gs=20 nc=0.1 ne=0.4 ps=15 xi=0.8 (14039.0 [based on 43 runs with cutoff 1000000000.0])

    Changing ["ps: 15->5"], evaluating ...
        -> worse: (14052.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["ne: 0.4->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 43 runs with cutoff 1000000000.0]) with flip 31

          
============= Performing 2 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 43 runs with cutoff 1000000000.0]) ============ 

State wants more detail (43+1) than incumbent (43), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 43 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 43 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 84.79999999999946, 14039.0 [44, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
State wants more detail (44+1) than incumbent (44), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 44 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 44 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 84.99999999999945, 14039.0 [45, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 2 bonus runs: gs=20 nc=0.1 ne=0.2 ps=15 xi=0.8 (14039.0 [based on 45 runs with cutoff 1000000000.0])

    Changing ["ps: 15->25"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=25 xi=0.8 (14039.0 [based on 45 runs with cutoff 1000000000.0]) with flip 32

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.8 (14039.0 [based on 45 runs with cutoff 1000000000.0]) ============ 

State wants more detail (45+1) than incumbent (45), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=25 xi=0.8 (14039.0 [based on 45 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 45 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 89.69999999999918, 14039.0 [46, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.8 (14039.0 [based on 46 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.6"], evaluating ...
904/1000, 90.39999999999914/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 46 runs with cutoff 1000000000.0]) with flip 33

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 46 runs with cutoff 1000000000.0]) ============ 

State wants more detail (46+1) than incumbent (46), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 46 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 46 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 94.4999999999989, 14039.0 [47, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 47 runs with cutoff 1000000000.0])

    Changing ["gs: 20->10"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 47 runs with cutoff 1000000000.0]) with flip 34

          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 47 runs with cutoff 1000000000.0]) ============ 

State wants more detail (47+1) than incumbent (47), doing incumbent first:
gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 47 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 47 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 99.39999999999863, 14039.0 [48, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 48 runs with cutoff 1000000000.0])

    Changing ["nc: 0.1->0.2"], evaluating ...
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
        -> worse: (14039.0 [based on 5 runs with cutoff 1000000000.0])
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 48 runs with cutoff 1000000000.0]) ============ 

ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          -> After 1 bonus runs for LM: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 48 runs with cutoff 1000000000.0])

   LM for iteration 1: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 48 runs with cutoff 1000000000.0])

========== DETAILED RESULTS (iteration 1): ==========
================================================

==================================================================
Best parameter configuration found so far (end of iteration 1): gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
==================================================================
Training quality of this incumbent parameter configuration: 14039.0, based on 48 runs with cutoff 1000000000.0
==================================================================

Comparing LM against incumbent:
gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (14039.0 [based on 48 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (14039.0 [based on 48 runs with cutoff 1000000000.0])
LM better, change incumbent
New Incumbent: 99.9999999999986, 14039.0 [48, 1000000000.0]. With state gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
Final solution for depth 1 with limit N=2000, and cutoff time=1000000000.0.
New Incumbent: 99.9999999999986, 14039.0 [48, 1000000000.0]. With state gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6

==================================================================
ParamILS is finished.
==================================================================

Final best parameter configuration found: gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6
==================================================================
Active parameters: gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6

==================================================================
Training quality of this final best found parameter configuration: 14039.0, based on 48 runs with cutoff 1000000000.0
==================================================================


==================================================================
Computing validation result on independent data -- 0 runs with cutoff time 1000000000.0...
==================================================================
Combined result: 1000000000000000000

================================================================
Final best parameter configuration: gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6
==================================================================
Active parameters: gs=10, nc=0.1, ne=0.2, ps=25, xi=0.6

================================================================
Training quality of this final best found parameter configuration: 14039.0, based on 48 runs with cutoff 1000000000.0
Test quality of this final best found parameter configuration: 1000000000000000000, based on 0 independent runs with cutoff 1000000000.0
==================================================================
