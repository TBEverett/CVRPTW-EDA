Call: /usr/bin/ruby ../scripts/param_ils_2_3_run.rb "-numRun" "0" "-approach" "focused" "-userunlog" "1" "-validN" "0" "-pruning" "0" "-maxEvals" "1000" "-scenariofile" "../_C1_2_6_baseTuning/scn/SolveVRP.scn"


seed: 1234
algo: bash SolveVRP.sh
tunerTimeout (CPU time): 100000000.0
maxWallTime: 8640000.0
maxEvals: 1000
run_obj: runlength
overall_obj: mean
instance_file: inst/single.inst
test_instance_file: inst/single.inst
N: 2000
cutoff_time: 1000000000.0
cutoff_length: 2147483647
R: 10
pertubation_strength_basic: 
pertubation_strength_scaling: false
p_restart: 0.01
Run 1
Level 
========================================================
Starting ILS for level 1, i.e. a limit of N=2000, and cutoff time=1000000000.0.
Current CPU time = 0, this run goes until 100000000.0 
========================================================
New Incumbent: 0, 100000000 [0, 0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
 Same incumbent, new precision:
New Incumbent: 0.1, 2686.0 [1, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> Take improving step to random gs=70 nc=0.8 ne=0.8 ps=5 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=20 nc=0.2 ne=0.4 ps=35 xi=0.8 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=100 nc=0.4 ne=0.4 ps=5 xi=0.1 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=100 nc=0.1 ne=0.2 ps=25 xi=0.1 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.1 ne=0.2 ps=35 xi=0.1 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.4 ne=0.6 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.6 ne=0.6 ps=25 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=70 nc=0.8 ne=0.4 ps=35 xi=0.8 (2686.0 [based on 1 runs with cutoff 1000000000.0])

          -> Take improving step to random gs=20 nc=0.8 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])

   BLS in iteration 1, start with gs=20 nc=0.8 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])
    Changing ["nc: 0.8->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0]) with flip 1

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0]) ============ 

State wants more detail (1+1) than incumbent (1), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 1 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 1 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.3, 2686.0 [2, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=45 xi=0.2 (2686.0 [based on 2 runs with cutoff 1000000000.0])

    Changing ["ps: 45->15"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (2686.0 [based on 2 runs with cutoff 1000000000.0]) with flip 2

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (2686.0 [based on 2 runs with cutoff 1000000000.0]) ============ 

State wants more detail (2+1) than incumbent (2), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (2686.0 [based on 2 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 2 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 1.7000000000000004, 2686.0 [3, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.2 (2686.0 [based on 3 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.1"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (2686.0 [based on 3 runs with cutoff 1000000000.0]) with flip 3

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (2686.0 [based on 3 runs with cutoff 1000000000.0]) ============ 

State wants more detail (3+1) than incumbent (3), doing incumbent first:
gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (2686.0 [based on 3 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 3 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 2.2000000000000006, 2686.0 [4, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.1 ps=15 xi=0.1 (2686.0 [based on 4 runs with cutoff 1000000000.0])

    Changing ["ne: 0.1->0.4"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (2686.0 [based on 4 runs with cutoff 1000000000.0]) with flip 4

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (2686.0 [based on 4 runs with cutoff 1000000000.0]) ============ 

State wants more detail (4+1) than incumbent (4), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (2686.0 [based on 4 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 4 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 2.800000000000001, 2686.0 [5, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=15 xi=0.1 (2686.0 [based on 5 runs with cutoff 1000000000.0])

    Changing ["ps: 15->25"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 5 runs with cutoff 1000000000.0]) with flip 5

          
============= Performing 1 bonus runs of state: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 5 runs with cutoff 1000000000.0]) ============ 

State wants more detail (5+1) than incumbent (5), doing incumbent first:
gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 5 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 5 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 3.5000000000000018, 2686.0 [6, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.2 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 6 runs with cutoff 1000000000.0])

    Changing ["nc: 0.2->0.6"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 6 runs with cutoff 1000000000.0]) with flip 6

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 6 runs with cutoff 1000000000.0]) ============ 

State wants more detail (6+1) than incumbent (6), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 6 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 6 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 4.300000000000001, 2686.0 [7, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=25 xi=0.1 (2686.0 [based on 7 runs with cutoff 1000000000.0])

    Changing ["ps: 25->5"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=5 xi=0.1 (2686.0 [based on 7 runs with cutoff 1000000000.0]) with flip 7

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=5 xi=0.1 (2686.0 [based on 7 runs with cutoff 1000000000.0]) ============ 

State wants more detail (7+1) than incumbent (7), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=5 xi=0.1 (2686.0 [based on 7 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 7 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 5.1999999999999975, 2686.0 [8, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=5 xi=0.1 (2686.0 [based on 8 runs with cutoff 1000000000.0])

    Changing ["xi: 0.1->0.8"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=5 xi=0.8 (2686.0 [based on 8 runs with cutoff 1000000000.0]) with flip 8

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=5 xi=0.8 (2686.0 [based on 8 runs with cutoff 1000000000.0]) ============ 

State wants more detail (8+1) than incumbent (8), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=5 xi=0.8 (2686.0 [based on 8 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 8 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 6.199999999999994, 2686.0 [9, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=5 xi=0.8 (2686.0 [based on 9 runs with cutoff 1000000000.0])

    Changing ["ps: 5->45"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=45 xi=0.8 (2686.0 [based on 9 runs with cutoff 1000000000.0]) with flip 9

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.8 (2686.0 [based on 9 runs with cutoff 1000000000.0]) ============ 

State wants more detail (9+1) than incumbent (9), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=45 xi=0.8 (2686.0 [based on 9 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 9 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 7.29999999999999, 2686.0 [10, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.8 (2686.0 [based on 10 runs with cutoff 1000000000.0])

    Changing ["xi: 0.8->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=45 xi=0.2 (2686.0 [based on 10 runs with cutoff 1000000000.0]) with flip 10

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.2 (2686.0 [based on 10 runs with cutoff 1000000000.0]) ============ 

State wants more detail (10+1) than incumbent (10), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=45 xi=0.2 (2686.0 [based on 10 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 10 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 8.499999999999986, 2686.0 [11, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.2 (2686.0 [based on 11 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.6"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 11 runs with cutoff 1000000000.0]) with flip 11

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 11 runs with cutoff 1000000000.0]) ============ 

State wants more detail (11+1) than incumbent (11), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 11 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 11 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 9.799999999999981, 2686.0 [12, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 12 runs with cutoff 1000000000.0])

    Changing ["ps: 45->25"], evaluating ...
101/1000, 10.09999999999998/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 12 runs with cutoff 1000000000.0]) with flip 12

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 12 runs with cutoff 1000000000.0]) ============ 

State wants more detail (12+1) than incumbent (12), doing incumbent first:
gs=20 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 12 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 12 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 11.199999999999976, 2686.0 [13, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 13 runs with cutoff 1000000000.0])

    Changing ["gs: 20->70"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 13 runs with cutoff 1000000000.0]) with flip 13

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 13 runs with cutoff 1000000000.0]) ============ 

State wants more detail (13+1) than incumbent (13), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 13 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 13 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 12.69999999999997, 2686.0 [14, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 14 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.2"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.2 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 14 runs with cutoff 1000000000.0]) with flip 14

          
============= Performing 1 bonus runs of state: gs=70 nc=0.2 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 14 runs with cutoff 1000000000.0]) ============ 

State wants more detail (14+1) than incumbent (14), doing incumbent first:
gs=70 nc=0.2 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 14 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 14 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 14.299999999999965, 2686.0 [15, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.2 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 15 runs with cutoff 1000000000.0])

    Changing ["ps: 25->15"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.2 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 15 runs with cutoff 1000000000.0]) with flip 15

          
============= Performing 1 bonus runs of state: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 15 runs with cutoff 1000000000.0]) ============ 

State wants more detail (15+1) than incumbent (15), doing incumbent first:
gs=70 nc=0.2 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 15 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 15 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 15.99999999999996, 2686.0 [16, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.2 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 16 runs with cutoff 1000000000.0])

    Changing ["nc: 0.2->0.6"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.6 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 16 runs with cutoff 1000000000.0]) with flip 16

          
============= Performing 1 bonus runs of state: gs=70 nc=0.6 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 16 runs with cutoff 1000000000.0]) ============ 

State wants more detail (16+1) than incumbent (16), doing incumbent first:
gs=70 nc=0.6 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 16 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 16 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 17.799999999999983, 2686.0 [17, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.6 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 17 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.8"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.8 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 17 runs with cutoff 1000000000.0]) with flip 17

          
============= Performing 1 bonus runs of state: gs=70 nc=0.8 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 17 runs with cutoff 1000000000.0]) ============ 

State wants more detail (17+1) than incumbent (17), doing incumbent first:
gs=70 nc=0.8 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 17 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 17 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 19.70000000000001, 2686.0 [18, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.8 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 18 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.1"], evaluating ...
201/1000, 20.100000000000016/100000000.0
          -> Take improving step to neighbour gs=70 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 18 runs with cutoff 1000000000.0]) with flip 18

          
============= Performing 1 bonus runs of state: gs=70 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 18 runs with cutoff 1000000000.0]) ============ 

State wants more detail (18+1) than incumbent (18), doing incumbent first:
gs=70 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 18 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 18 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 21.70000000000004, 2686.0 [19, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 19 runs with cutoff 1000000000.0])

    Changing ["gs: 70->100"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 19 runs with cutoff 1000000000.0]) with flip 19

          
============= Performing 1 bonus runs of state: gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 19 runs with cutoff 1000000000.0]) ============ 

State wants more detail (19+1) than incumbent (19), doing incumbent first:
gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 19 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 19 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 23.800000000000068, 2686.0 [20, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.1 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 20 runs with cutoff 1000000000.0])

    Changing ["nc: 0.1->0.4"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 20 runs with cutoff 1000000000.0]) with flip 20

          
============= Performing 1 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 20 runs with cutoff 1000000000.0]) ============ 

State wants more detail (20+1) than incumbent (20), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 20 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 20 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 26.0000000000001, 2686.0 [21, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.4 ne=0.4 ps=15 xi=0.6 (2686.0 [based on 21 runs with cutoff 1000000000.0])

    Changing ["ps: 15->35"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=35 xi=0.6 (2686.0 [based on 21 runs with cutoff 1000000000.0]) with flip 21

          
============= Performing 1 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=35 xi=0.6 (2686.0 [based on 21 runs with cutoff 1000000000.0]) ============ 

State wants more detail (21+1) than incumbent (21), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=35 xi=0.6 (2686.0 [based on 21 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 21 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 28.300000000000132, 2686.0 [22, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.4 ne=0.4 ps=35 xi=0.6 (2686.0 [based on 22 runs with cutoff 1000000000.0])

    Changing ["ps: 35->45"], evaluating ...
301/1000, 30.100000000000158/100000000.0
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 22 runs with cutoff 1000000000.0]) with flip 22

          
============= Performing 1 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 22 runs with cutoff 1000000000.0]) ============ 

State wants more detail (22+1) than incumbent (22), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 22 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 22 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 30.700000000000166, 2686.0 [23, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.4 ne=0.4 ps=45 xi=0.6 (2686.0 [based on 23 runs with cutoff 1000000000.0])

    Changing ["xi: 0.6->0.1"], evaluating ...
          -> Take improving step to neighbour gs=100 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 23 runs with cutoff 1000000000.0]) with flip 23

          
============= Performing 1 bonus runs of state: gs=100 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 23 runs with cutoff 1000000000.0]) ============ 

State wants more detail (23+1) than incumbent (23), doing incumbent first:
gs=100 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 23 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 23 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 33.2000000000002, 2686.0 [24, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=100 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 24 runs with cutoff 1000000000.0])

    Changing ["gs: 100->40"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 24 runs with cutoff 1000000000.0]) with flip 24

          
============= Performing 1 bonus runs of state: gs=40 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 24 runs with cutoff 1000000000.0]) ============ 

State wants more detail (24+1) than incumbent (24), doing incumbent first:
gs=40 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 24 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 24 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 35.80000000000024, 2686.0 [25, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.4 ne=0.4 ps=45 xi=0.1 (2686.0 [based on 25 runs with cutoff 1000000000.0])

    Changing ["ne: 0.4->0.6"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.4 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 25 runs with cutoff 1000000000.0]) with flip 25

          
============= Performing 1 bonus runs of state: gs=40 nc=0.4 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 25 runs with cutoff 1000000000.0]) ============ 

State wants more detail (25+1) than incumbent (25), doing incumbent first:
gs=40 nc=0.4 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 25 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 25 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 38.50000000000028, 2686.0 [26, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.4 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 26 runs with cutoff 1000000000.0])

    Changing ["nc: 0.4->0.1"], evaluating ...
401/1000, 40.1000000000003/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.1 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 26 runs with cutoff 1000000000.0]) with flip 26

          
============= Performing 1 bonus runs of state: gs=40 nc=0.1 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 26 runs with cutoff 1000000000.0]) ============ 

State wants more detail (26+1) than incumbent (26), doing incumbent first:
gs=40 nc=0.1 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 26 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 26 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 41.30000000000032, 2686.0 [27, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.1 ne=0.6 ps=45 xi=0.1 (2686.0 [based on 27 runs with cutoff 1000000000.0])

    Changing ["xi: 0.1->0.6"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.1 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 27 runs with cutoff 1000000000.0]) with flip 27

          
============= Performing 1 bonus runs of state: gs=40 nc=0.1 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 27 runs with cutoff 1000000000.0]) ============ 

State wants more detail (27+1) than incumbent (27), doing incumbent first:
gs=40 nc=0.1 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 27 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 27 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 44.20000000000036, 2686.0 [28, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.1 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 28 runs with cutoff 1000000000.0])

    Changing ["nc: 0.1->0.8"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 28 runs with cutoff 1000000000.0]) with flip 28

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 28 runs with cutoff 1000000000.0]) ============ 

State wants more detail (28+1) than incumbent (28), doing incumbent first:
gs=40 nc=0.8 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 28 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 28 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 47.2000000000004, 2686.0 [29, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.6 ps=45 xi=0.6 (2686.0 [based on 29 runs with cutoff 1000000000.0])

    Changing ["ne: 0.6->0.8"], evaluating ...
501/1000, 50.10000000000044/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.8 ps=45 xi=0.6 (2686.0 [based on 29 runs with cutoff 1000000000.0]) with flip 29

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.8 ps=45 xi=0.6 (2686.0 [based on 29 runs with cutoff 1000000000.0]) ============ 

State wants more detail (29+1) than incumbent (29), doing incumbent first:
gs=40 nc=0.8 ne=0.8 ps=45 xi=0.6 (2686.0 [based on 29 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 29 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 50.300000000000445, 2686.0 [30, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.8 ps=45 xi=0.6 (2686.0 [based on 30 runs with cutoff 1000000000.0])

    Changing ["ps: 45->25"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.8 ps=25 xi=0.6 (2686.0 [based on 30 runs with cutoff 1000000000.0]) with flip 30

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.8 ps=25 xi=0.6 (2686.0 [based on 30 runs with cutoff 1000000000.0]) ============ 

State wants more detail (30+1) than incumbent (30), doing incumbent first:
gs=40 nc=0.8 ne=0.8 ps=25 xi=0.6 (2686.0 [based on 30 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 30 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 53.50000000000049, 2686.0 [31, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.8 ps=25 xi=0.6 (2686.0 [based on 31 runs with cutoff 1000000000.0])

    Changing ["xi: 0.6->0.4"], evaluating ...
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.8 ps=25 xi=0.4 (2686.0 [based on 31 runs with cutoff 1000000000.0]) with flip 31

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.8 ps=25 xi=0.4 (2686.0 [based on 31 runs with cutoff 1000000000.0]) ============ 

State wants more detail (31+1) than incumbent (31), doing incumbent first:
gs=40 nc=0.8 ne=0.8 ps=25 xi=0.4 (2686.0 [based on 31 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 31 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 56.80000000000054, 2686.0 [32, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.8 ps=25 xi=0.4 (2686.0 [based on 32 runs with cutoff 1000000000.0])

    Changing ["ne: 0.8->0.2"], evaluating ...
601/1000, 60.100000000000584/100000000.0
          -> Take improving step to neighbour gs=40 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 32 runs with cutoff 1000000000.0]) with flip 32

          
============= Performing 1 bonus runs of state: gs=40 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 32 runs with cutoff 1000000000.0]) ============ 

State wants more detail (32+1) than incumbent (32), doing incumbent first:
gs=40 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 32 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 32 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 60.200000000000585, 2686.0 [33, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=40 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 33 runs with cutoff 1000000000.0])

    Changing ["gs: 40->10"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 33 runs with cutoff 1000000000.0]) with flip 33

          
============= Performing 1 bonus runs of state: gs=10 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 33 runs with cutoff 1000000000.0]) ============ 

State wants more detail (33+1) than incumbent (33), doing incumbent first:
gs=10 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 33 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 33 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 63.700000000000635, 2686.0 [34, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 34 runs with cutoff 1000000000.0])

    Changing ["gs: 10->70"], evaluating ...
          -> Take improving step to neighbour gs=70 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 34 runs with cutoff 1000000000.0]) with flip 34

          
============= Performing 1 bonus runs of state: gs=70 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 34 runs with cutoff 1000000000.0]) ============ 

State wants more detail (34+1) than incumbent (34), doing incumbent first:
gs=70 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 34 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 34 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 67.30000000000045, 2686.0 [35, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=70 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 35 runs with cutoff 1000000000.0])

    Changing ["gs: 70->20"], evaluating ...
702/1000, 70.20000000000029/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 35 runs with cutoff 1000000000.0]) with flip 35

          
============= Performing 1 bonus runs of state: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 35 runs with cutoff 1000000000.0]) ============ 

State wants more detail (35+1) than incumbent (35), doing incumbent first:
gs=20 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 35 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 35 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 71.00000000000024, 2686.0 [36, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.4 (2686.0 [based on 36 runs with cutoff 1000000000.0])

    Changing ["xi: 0.4->0.6"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.8 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 36 runs with cutoff 1000000000.0]) with flip 36

          
============= Performing 1 bonus runs of state: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 36 runs with cutoff 1000000000.0]) ============ 

State wants more detail (36+1) than incumbent (36), doing incumbent first:
gs=20 nc=0.8 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 36 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 36 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 74.80000000000003, 2686.0 [37, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 37 runs with cutoff 1000000000.0])

    Changing ["xi: 0.6->0.2"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.8 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 37 runs with cutoff 1000000000.0]) with flip 37

          
============= Performing 1 bonus runs of state: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 37 runs with cutoff 1000000000.0]) ============ 

State wants more detail (37+1) than incumbent (37), doing incumbent first:
gs=20 nc=0.8 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 37 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 37 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 78.6999999999998, 2686.0 [38, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.8 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 38 runs with cutoff 1000000000.0])

    Changing ["nc: 0.8->0.6"], evaluating ...
803/1000, 80.29999999999971/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.6 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 38 runs with cutoff 1000000000.0]) with flip 38

          
============= Performing 1 bonus runs of state: gs=20 nc=0.6 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 38 runs with cutoff 1000000000.0]) ============ 

State wants more detail (38+1) than incumbent (38), doing incumbent first:
gs=20 nc=0.6 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 38 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 38 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 82.69999999999958, 2686.0 [39, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.6 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 39 runs with cutoff 1000000000.0])

    Changing ["nc: 0.6->0.1"], evaluating ...
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 39 runs with cutoff 1000000000.0]) with flip 39

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 39 runs with cutoff 1000000000.0]) ============ 

State wants more detail (39+1) than incumbent (39), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 39 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 39 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 86.79999999999934, 2686.0 [40, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.2 (2686.0 [based on 40 runs with cutoff 1000000000.0])

    Changing ["xi: 0.2->0.6"], evaluating ...
904/1000, 90.39999999999914/100000000.0
          -> Take improving step to neighbour gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 40 runs with cutoff 1000000000.0]) with flip 40

          
============= Performing 1 bonus runs of state: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 40 runs with cutoff 1000000000.0]) ============ 

State wants more detail (40+1) than incumbent (40), doing incumbent first:
gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 40 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 40 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 90.9999999999991, 2686.0 [41, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=20 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 41 runs with cutoff 1000000000.0])

    Changing ["gs: 20->10"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 41 runs with cutoff 1000000000.0]) with flip 41

          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 41 runs with cutoff 1000000000.0]) ============ 

State wants more detail (41+1) than incumbent (41), doing incumbent first:
gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 41 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 41 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 95.29999999999886, 2686.0 [42, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.1 ne=0.2 ps=25 xi=0.6 (2686.0 [based on 42 runs with cutoff 1000000000.0])

    Changing ["ne: 0.2->0.4"], evaluating ...
          -> Take improving step to neighbour gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 42 runs with cutoff 1000000000.0]) with flip 42

          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 42 runs with cutoff 1000000000.0]) ============ 

State wants more detail (42+1) than incumbent (42), doing incumbent first:
gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 42 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 42 runs with cutoff 1000000000.0])
 Same incumbent, new precision:
New Incumbent: 99.69999999999861, 2686.0 [43, 1000000000.0]. With state gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
          -> After 1 bonus runs: gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 43 runs with cutoff 1000000000.0])

    Changing ["xi: 0.6->0.4"], evaluating ...
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
        -> worse: (2686.0 [based on 2 runs with cutoff 1000000000.0])
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          
============= Performing 1 bonus runs of state: gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 43 runs with cutoff 1000000000.0]) ============ 

ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
          -> After 1 bonus runs for LM: gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 43 runs with cutoff 1000000000.0])

   LM for iteration 1: gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 43 runs with cutoff 1000000000.0])

========== DETAILED RESULTS (iteration 1): ==========
================================================

==================================================================
Best parameter configuration found so far (end of iteration 1): gs=40, nc=0.4, ne=0.4, ps=25, xi=0.4
==================================================================
Training quality of this incumbent parameter configuration: 2686.0, based on 43 runs with cutoff 1000000000.0
==================================================================

Comparing LM against incumbent:
gs=10 nc=0.1 ne=0.4 ps=25 xi=0.6 (2686.0 [based on 43 runs with cutoff 1000000000.0])
gs=40 nc=0.4 ne=0.4 ps=25 xi=0.4 (2686.0 [based on 43 runs with cutoff 1000000000.0])
LM better, change incumbent
New Incumbent: 99.9999999999986, 2686.0 [43, 1000000000.0]. With state gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6
ParamILS has reached the specified maximum number of 1000 function evaluations => stopping the search now.
Final solution for depth 1 with limit N=2000, and cutoff time=1000000000.0.
New Incumbent: 99.9999999999986, 2686.0 [43, 1000000000.0]. With state gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6

==================================================================
ParamILS is finished.
==================================================================

Final best parameter configuration found: gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6
==================================================================
Active parameters: gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6

==================================================================
Training quality of this final best found parameter configuration: 2686.0, based on 43 runs with cutoff 1000000000.0
==================================================================


==================================================================
Computing validation result on independent data -- 0 runs with cutoff time 1000000000.0...
==================================================================
Combined result: 1000000000000000000

================================================================
Final best parameter configuration: gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6
==================================================================
Active parameters: gs=10, nc=0.1, ne=0.4, ps=25, xi=0.6

================================================================
Training quality of this final best found parameter configuration: 2686.0, based on 43 runs with cutoff 1000000000.0
Test quality of this final best found parameter configuration: 1000000000000000000, based on 0 independent runs with cutoff 1000000000.0
==================================================================
